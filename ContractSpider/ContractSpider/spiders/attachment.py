import os
import json
import logging

import scrapy
import pandas as pd
from datetime import datetime

from filetype import filetype
from scrapy.utils.project import get_project_settings
from tqdm import tqdm
from urllib.parse import urlparse, parse_qs
import mimetypes
import requests

# åŠ äº†ä¿®æ”¹5.11

class AttachmentSpider(scrapy.Spider):
    name = "attachment"

    custom_settings = {
        'DOWNLOADER_MIDDLEWARES': {
            'ContractSpider.middlewares.AttachmentProxyMiddleware': 300,
        },
        'LOG_ENABLED': False,
    }

    ACCEPTED_MIME_TYPES = {
        "application/pdf",
        "application/zip",
        "application/msword",
        "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        "application/vnd.ms-excel",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        "application/octet-stream",
        "image/jpeg",
        "image/png",
        "image/gif",
        "audio/mpeg",
        "video/mp4",
        "application/json"
    }

    MIME_EXTENSION_MAP = {
        "application/wps-office.et": ".et",
        "application/wps-office.dps": ".dps",
        "application/wps-office.wps": ".wps",
        "application/pdf": ".pdf",
        "application/msword": ".doc",
        "application/vnd.ms-excel": ".xls",
        "application/vnd.openxmlformats-officedocument.wordprocessingml.document": ".docx",
        "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet": ".xlsx",
        "application/zip": ".zip",
        "application/octet-stream": "",  # fallback
        "application/x-rar": ".rar",
        "image/jpeg": ".jpg",
        "image/png": ".png",
        "image/gif": ".gif",
        "text/plain": ".txt"
    }

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.settings = get_project_settings()
        self.start_date = kwargs.get("ATTACHMENT_START_DATE")
        self.end_date = kwargs.get("ATTACHMENT_END_DATE")
        self.retry_failed = kwargs.get("retry_failed", "0") == "1"  # æ–°å¢å‚æ•°ï¼Œç”¨äºæ§åˆ¶æ˜¯å¦é‡è·‘å¤±è´¥ä»»åŠ¡
        self.max_retry = 3

        today = datetime.now()
        log_filename = f"attachment_{today.year}_{today.month:02d}_{today.day:02d}.log"
        log_path = os.path.join("logs", log_filename)
        os.makedirs("logs", exist_ok=True)

        logging.basicConfig(
            filename=log_path,
            level=logging.INFO,
            format="%(asctime)s [%(levelname)s] %(message)s",
            filemode='w',
        )

        self.custom_logger = logging.getLogger("AttachmentSpider")
        self.custom_logger.setLevel(logging.INFO)
        handler = logging.FileHandler(log_path, encoding="utf-8")
        formatter = logging.Formatter('[%(levelname)s] %(asctime)s - %(filename)s:%(lineno)d - %(message)s')
        handler.setFormatter(formatter)
        self.custom_logger.addHandler(handler)
        self.custom_logger.propagate = False
        self.custom_logger.info("æ—¥å¿—åˆå§‹åŒ–å®Œæˆ âœ…")

        if not self.start_date:
            self.start_date = self.settings.get('ATTACHMENT_START_DATE')
        if not self.end_date:
            self.end_date = self.settings.get('ATTACHMENT_END_DATE')

        self.downloads_folder = "detail_downloads"
        self.save_folder = "attachments"
        self.target_column = "é™„ä»¶ä¸‹è½½é“¾æ¥"
        self.contract_number_column = "åˆåŒç¼–å·"
        self.contract_name_column = "åˆåŒåç§°"
        
        self.failed_tasks_path = os.path.join("logs", "failed_downloads.json")
        
        if self.retry_failed:
            self.custom_logger.info("ğŸ“¢ æ­£åœ¨é‡è·‘å¤±è´¥ä»»åŠ¡æ¨¡å¼...")
            self.attachment_data = self.load_failed_tasks()
        else:
            self.attachment_data = self.extract_links()
        
        self.progress_bar = None

    def load_failed_tasks(self):
        """åŠ è½½å¤±è´¥çš„ä¸‹è½½ä»»åŠ¡"""
        if not os.path.exists(self.failed_tasks_path):
            self.custom_logger.warning(f"âš ï¸ æœªæ‰¾åˆ°å¤±è´¥ä»»åŠ¡è®°å½•æ–‡ä»¶: {self.failed_tasks_path}")
            return []
            
        try:
            with open(self.failed_tasks_path, "r", encoding="utf-8") as f:
                failed_tasks = json.load(f)
                
            # å°†å¤±è´¥ä»»åŠ¡è½¬æ¢ä¸ºä¸extract_links()ç›¸åŒçš„æ ¼å¼
            formatted_tasks = []
            for task in failed_tasks:
                url = task.get("url")
                file_name = task.get("file_name")
                folder_name = task.get("folder_name")
                
                # ç¡®ä¿folder_nameå­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®
                if not folder_name or not isinstance(folder_name, str):
                    # å°è¯•ä»æ–‡ä»¶åä¸­æå–æ—¥æœŸï¼ˆå¦‚æœæœ‰ï¼‰
                    try:
                        # å‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º"åˆåŒç¼–å·_åˆåŒåç§°_1.pdf"
                        parts = file_name.split("_")
                        if len(parts) >= 3:
                            # å°è¯•ä»æ–‡ä»¶åçš„ç¬¬ä¸€éƒ¨åˆ†ï¼ˆåˆåŒç¼–å·ï¼‰ä¸­æå–å¹´æœˆ
                            contract_number = parts[0]
                            if contract_number.startswith("20") and len(contract_number) >= 6:
                                year_month = contract_number[:6]  # å¦‚"202211"
                                folder_name = f"{year_month[:4]}-{year_month[4:6]}"  # å˜ä¸º"2022-11"
                            else:
                                folder_name = "é‡è¯•ä»»åŠ¡"
                        else:
                            folder_name = "é‡è¯•ä»»åŠ¡"
                    except Exception:
                        folder_name = "é‡è¯•ä»»åŠ¡"
                        
                self.custom_logger.info(f"ğŸ“ å¤±è´¥ä»»åŠ¡ä½¿ç”¨æ–‡ä»¶å¤¹: {folder_name}, æ–‡ä»¶: {file_name}")
                
                if not url or not file_name:
                    continue
                    
                formatted_tasks.append({
                    "url": url,
                    "file_name": file_name,
                    "folder_name": folder_name
                })
                
            self.custom_logger.info(f"âœ… åŠ è½½äº† {len(formatted_tasks)} ä¸ªå¤±è´¥ä»»åŠ¡")
            
                
            return formatted_tasks
        except Exception as e:
            self.custom_logger.error(f"âŒ è¯»å–å¤±è´¥ä»»åŠ¡æ–‡ä»¶å‡ºé”™: {e}")
            return []

    def extract_links(self):
        attachment_list = []

        try:
            start_dt = datetime.strptime(self.start_date, "%Y-%m-%d")
            end_dt = datetime.strptime(self.end_date, "%Y-%m-%d")
        except Exception as e:
            self.custom_logger.error(f"âš ï¸ æ—¥æœŸæ ¼å¼é”™è¯¯: {e}")
            return []

        for folder_name in os.listdir(self.downloads_folder):
            folder_path = os.path.join(self.downloads_folder, folder_name)
            if not os.path.isdir(folder_path):
                continue

            for file_name in os.listdir(folder_path):
                if not file_name.endswith(".xlsx"):
                    continue

                # ä»æ–‡ä»¶åä¸­è§£æå‡ºæ—¥æœŸéƒ¨åˆ†ï¼ˆå‡è®¾æ–‡ä»¶åæ ¼å¼ä¸º yyyy-mm-dd.xlsxï¼‰
                try:
                    file_date = datetime.strptime(file_name.replace(".xlsx", ""), "%Y-%m-%d")
                except ValueError:
                    continue  # è·³è¿‡éæ—¥æœŸå‘½åçš„æ–‡ä»¶

                if start_dt <= file_date <= end_dt:
                    file_path = os.path.join(folder_path, file_name)
                    attachment_list.extend(self.process_excel(file_path))

        return attachment_list

    def process_excel(self, file_path):
        try:
            df = pd.read_excel(file_path, engine="openpyxl")
        except Exception as e:
            self.custom_logger.error(f"âŒ æ— æ³•è¯»å– Excel æ–‡ä»¶ {file_path}ï¼Œè·³è¿‡å¤„ç†ã€‚é”™è¯¯ä¿¡æ¯: {e}")
            return []

        if self.target_column not in df.columns or \
           self.contract_number_column not in df.columns or \
           self.contract_name_column not in df.columns:
            self.custom_logger.error(f"âš ï¸ {file_path} ç¼ºå°‘å¿…è¦åˆ—ï¼Œè·³è¿‡å¤„ç†ã€‚")
            return []

        attachment_list = []
        for _, row in df.iterrows():
            contract_date = row.get("åˆåŒå…¬å‘Šæ—¥æœŸ", "")
            if not self.is_within_date_range(contract_date):
                continue

            contract_number = row[self.contract_number_column]
            contract_name = row[self.contract_name_column]
            attachment_links = row[self.target_column]

            if pd.isna(attachment_links):
                continue

            links = [link.strip() for link in str(attachment_links).split(",") if link.strip()]
            for index, link in enumerate(links, start=1):
                try:
                    folder_name = datetime.strptime(contract_date, "%Y-%m-%d").strftime("%Y-%m")
                except Exception:
                    folder_name = "æœªçŸ¥æ—¥æœŸ"
                # å¹¶ä¸æ˜¯å…¨éƒ½æ˜¯PDF
                ext = self.get_file_extension(link)
                save_name = f"{contract_number}_{contract_name}_{index}{ext}"
                attachment_list.append({
                    "folder_name": folder_name,
                    "file_name": save_name,
                    "url": link
                })

        self.custom_logger.info(f"âœ… ä»{file_path}ä¸­æå–åˆ°: {len(attachment_list)} ä¸ªé“¾æ¥")
        return attachment_list

    def is_within_date_range(self, contract_date):
        if not contract_date or pd.isna(contract_date):
            return False
        try:
            contract_date = datetime.strptime(str(contract_date), "%Y-%m-%d")
        except ValueError:
            return False
        if self.start_date and contract_date < datetime.strptime(self.start_date, "%Y-%m-%d"):
            return False
        if self.end_date and contract_date > datetime.strptime(self.end_date, "%Y-%m-%d"):
            return False
        return True

    def start_requests(self):
        total_files = len(self.attachment_data)
        self.progress_bar = tqdm(total=total_files, desc="ä¸‹è½½è¿›åº¦", ncols=80)
        
        if total_files == 0:
            self.custom_logger.warning("âš ï¸ æ²¡æœ‰å¯ä¸‹è½½çš„é™„ä»¶")
            return
            
        mode = "é‡è·‘å¤±è´¥ä»»åŠ¡" if self.retry_failed else "æ­£å¸¸ä¸‹è½½"
        self.custom_logger.info(f"ğŸš€ å¼€å§‹{mode}ï¼Œå…± {total_files} ä¸ªæ–‡ä»¶")

        for item in self.attachment_data:
            folder_path = os.path.join(self.save_folder, item["folder_name"])
            os.makedirs(folder_path, exist_ok=True)
            file_path = os.path.join(folder_path, item["file_name"])
            if os.path.exists(file_path):
                self.custom_logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {file_path}")
                self.progress_bar.update(1)
                continue

            request = scrapy.Request(
                method="GET",
                url=item["url"],
                headers={
                    'Connection': 'close',
                    'Referer': 'http://htgs.ccgp.gov.cn/',
                },
                meta={
                    "file_path": file_path,
                    "file_name": item["file_name"],
                    "folder_name": item["folder_name"],
                    "retry_count": 0,
                },
                callback=self.save_attachment,
                errback=self.handle_error
            )
            yield request

    def save_attachment(self, response):
        file_path = response.meta["file_path"]
        self.custom_logger.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {file_path}")
        # ä¿å­˜åŸå§‹æ–‡ä»¶
        with open(file_path, "wb") as f:
            f.write(response.body)
            self.custom_logger.info(f"âœ… åŸå§‹æ–‡ä»¶ä¿å­˜æˆåŠŸ: {file_path}")

        # å¦‚æœæ–‡ä»¶æ²¡æœ‰åç¼€åï¼Œå°è¯•è¯†åˆ«æ–‡ä»¶ç±»å‹å¹¶é‡å‘½å
        base, ext = os.path.splitext(file_path)
        if not ext:
            kind = filetype.guess(response.body)
            if kind:
                extension = kind.extension
                if extension == 'xls':
                    extension = 'docx'
                new_file_path = f"{file_path}.{extension}"
                os.rename(file_path, new_file_path)
                file_path = new_file_path
                self.custom_logger.info(f"ğŸ” æ–‡ä»¶ç±»å‹è¯†åˆ«æˆåŠŸï¼Œé‡å‘½åä¸º: {file_path}")
            else:
                self.custom_logger.warning(f"âš ï¸ æ— æ³•è¯†åˆ«æ–‡ä»¶ç±»å‹ï¼Œä¿æŒåŸå§‹æ–‡ä»¶å: {file_path}")
        else:
            self.custom_logger.info(f"âœ… æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡é‡å‘½å: {file_path}")

        self.custom_logger.info(f"âœ… ä¸‹è½½æˆåŠŸ: {file_path}")
        self.progress_bar.update(1)

    def handle_error(self, failure):
        request = failure.request
        retry_count = request.meta.get("retry_count", 0)
        file_path = request.meta.get("file_path")
        file_name = request.meta.get("file_name")
        folder_name = request.meta.get("folder_name")

        if retry_count < self.max_retry:
            new_request = request.copy()
            new_request.meta["retry_count"] = retry_count + 1
            self.custom_logger.warning(f"âš ï¸ ç¬¬ {retry_count + 1} æ¬¡é‡è¯•: {request.url}")
            yield new_request
        else:
            self.custom_logger.error(f"âŒ æœ€ç»ˆå¤±è´¥: {request.url} => {file_path}")
            # è®°å½•æ–‡ä»¶å¤¹ä¿¡æ¯çš„åŒæ—¶æ‰“å°æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•
            self.custom_logger.info(f"ğŸ“ è®°å½•å¤±è´¥ä»»åŠ¡ï¼Œæ–‡ä»¶å¤¹: {folder_name}, æ–‡ä»¶: {file_name}")
            failed_item = {
                "url": request.url, 
                "file_name": file_name,
                "folder_name": folder_name
            }
            self.save_failed_task(failed_item)
            self.progress_bar.update(1)

    def save_failed_task(self, failed_item):
        try:
            if os.path.exists(self.failed_tasks_path):
                with open(self.failed_tasks_path, "r", encoding="utf-8") as f:
                    data = json.load(f)
            else:
                data = []
        except Exception as e:
            self.custom_logger.error(f"âŒ è¯»å–å¤±è´¥æ–‡ä»¶è®°å½•å‡ºé”™ï¼š{e}")
            data = []

        data.append(failed_item)

        try:
            with open(self.failed_tasks_path, "w", encoding="utf-8") as f:
                json.dump(data, f, indent=4, ensure_ascii=False)
            self.custom_logger.info(f"ğŸ’¾ ä¿å­˜å¤±è´¥è®°å½•æˆåŠŸ: {failed_item.get('file_name')}")
        except Exception as e:
            self.custom_logger.error(f"âŒ ä¿å­˜å¤±è´¥è®°å½•å‡ºé”™ï¼š{e}")

    def closed(self, reason):
        if self.progress_bar:
            self.progress_bar.close()
        self.custom_logger.info(f"çˆ¬è™«ç»“æŸï¼ŒåŸå› ï¼š{reason}")

    def get_file_extension(self, url):
        # 1. ä» URL è·¯å¾„ä¸­æå–
        path = urlparse(url).path
        _, ext = os.path.splitext(path)
        if ext:
            return ext

        # 2. ä» URL å‚æ•°ä¸­æå–
        query = urlparse(url).query
        params = parse_qs(query)
        for value_list in params.values():
            for value in value_list:
                _, ext = os.path.splitext(value)
                if ext:
                    return ext

        # 3. ä» Content-Type åˆ¤æ–­ï¼ˆå¢åŠ è¿‡æ»¤ï¼‰
        try:
            response = requests.head(url, allow_redirects=True, timeout=5)
            content_type = response.headers.get('Content-Type', '').split(';')[0].strip()
            if content_type in self.ACCEPTED_MIME_TYPES:
                guessed_ext = mimetypes.guess_extension(content_type)
                if guessed_ext:
                    return guessed_ext
        except Exception:
            pass

        # 4. æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥æ—¶è¿”å›ç©ºå­—ç¬¦ä¸²
        return ''
